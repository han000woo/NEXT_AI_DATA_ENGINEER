# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install gradio -q

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import BatchNormalization
import numpy as np
import os
import zipfile
import gradio as gr

# ==========================================
# [ì¤‘ìš”] ì—¬ê¸°ì— ë‚´ ZIP íŒŒì¼ ì´ë¦„ì„ ì ì–´ì£¼ì„¸ìš”
# ==========================================
local_zip_filename = 'cats_and_dogs_filtered.zip'  # ì˜ˆ: 'my_data.zip'

# 2. ì••ì¶• í•´ì œ (ì´ë¯¸ í’€ë ¤ìˆìœ¼ë©´ ê±´ë„ˆëœ€)
base_dir = '/content/dataset' # ì••ì¶•ì„ í’€ í´ë” ê²½ë¡œ

if not os.path.exists(base_dir):
    print(f"'{local_zip_filename}' ì••ì¶• í•´ì œ ì¤‘...")
    with zipfile.ZipFile(local_zip_filename, 'r') as zip_ref:
        zip_ref.extractall(base_dir)
    print("ì••ì¶• í•´ì œ ì™„ë£Œ!")
else:
    print("ì´ë¯¸ ì••ì¶•ì´ í•´ì œëœ í´ë”ê°€ ìˆìŠµë‹ˆë‹¤.")

# 3. ë°ì´í„° ê²½ë¡œ ì„¤ì •
# ì£¼ì˜: ì••ì¶• íŒŒì¼ ë‚´ë¶€ êµ¬ì¡°ì— ë”°ë¼ ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ë³´í†µ ì••ì¶•ì„ í’€ë©´ ìµœìƒìœ„ í´ë”ê°€ í•˜ë‚˜ ë” ìƒê¸°ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
# í™•ì¸ì„ ìœ„í•´ í´ë” êµ¬ì¡°ë¥¼ ì¶œë ¥í•´ë´…ë‹ˆë‹¤.
print(f"í´ë” êµ¬ì¡° í™•ì¸: {os.listdir(base_dir)}")

# ë§Œì•½ ì••ì¶• í’€ë¦° í´ë” ì•ˆì— 'cats_and_dogs_filtered' ê°™ì€ í´ë”ê°€ ë˜ ìˆë‹¤ë©´ ì•„ë˜ ê²½ë¡œì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
# ì˜ˆ: os.path.join(base_dir, 'cats_and_dogs_filtered', 'train')
train_dir = os.path.join(base_dir, 'cats_and_dogs_filtered', 'train')
validation_dir = os.path.join(base_dir, 'cats_and_dogs_filtered', 'validation')

# 4. ë°ì´í„° ì „ì²˜ë¦¬ (ResNet ì „ìš©)
IMG_HEIGHT = 224
IMG_WIDTH = 224
batch_size = 32

train_image_generator = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

validation_image_generator = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

# ë°ì´í„° ë¡œë”© ì‹œë„ (ê²½ë¡œ ì—ëŸ¬ ë°©ì§€ìš© try-except)
try:
    train_data_gen = train_image_generator.flow_from_directory(
        batch_size=batch_size,
        directory=train_dir,
        shuffle=True,
        target_size=(IMG_HEIGHT, IMG_WIDTH),
        class_mode='binary'
    )

    val_data_gen = validation_image_generator.flow_from_directory(
        batch_size=batch_size,
        directory=validation_dir,
        target_size=(IMG_HEIGHT, IMG_WIDTH),
        class_mode='binary'
    )
except FileNotFoundError:
    print("âŒ ì˜¤ë¥˜: 'train' ë˜ëŠ” 'validation' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"í˜„ì¬ '{base_dir}' ì•ˆì— ìˆëŠ” í´ë” ëª©ë¡: {os.listdir(base_dir)}")
    print("ê²½ë¡œ ì„¤ì • ë¶€ë¶„(train_dir, validation_dir)ì„ ì‹¤ì œ í´ë” êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
    raise # ì½”ë“œ ì‹¤í–‰ ì¤‘ë‹¨

# 5. ResNet50 ëª¨ë¸ ìƒì„±
base_model = ResNet50(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),
                      include_top=False,
                      weights='imagenet')
base_model.trainable = False

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    BatchNormalization(),
    Dense(256, activation='relu'),
    Dropout(0.4),
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# 6. í•™ìŠµ ì‹œì‘
print("í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
history = model.fit(
    train_data_gen,
    steps_per_epoch=len(train_data_gen),
    epochs=10,
    validation_data=val_data_gen,
    validation_steps=len(val_data_gen)
)

# 1. ëª¨ë¸ ì €ì¥ (.keras í˜•ì‹ ê¶Œì¥)
save_path = 'cat_dog_resnet_model.keras'
model.save(save_path)

print(f"ëª¨ë¸ì´ '{save_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 7. Gradio ì¸í„°í˜ì´ìŠ¤
def classify_image(image):
    image = image.resize((IMG_WIDTH, IMG_HEIGHT))
    img_array = np.array(image)
    img_array = preprocess_input(img_array)
    img_array = np.expand_dims(img_array, axis=0)
    prediction = model.predict(img_array)[0][0]
    if prediction < 0.5:
        return f"ğŸ± ê³ ì–‘ì´ ({ (1-prediction)*100:.1f}% )"
    else:
        return f"ğŸ¶ ê°•ì•„ì§€ ({ prediction*100:.1f}% )"

interface = gr.Interface(fn=classify_image, inputs=gr.Image(type="pil"), outputs="text")
interface.launch(share=True)