import asyncio
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import json
import pandas as pd
from backend.chat_service import get_chat_service
from backend.mcp_service import mcp_query_db
from config.mcp_tool import tools_schema
from datetime import datetime
import plotly.express as px

from enums.target import AnswerTarget

# -------------------------------------------------------------------------
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# -------------------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parents[1]
CONFIG_PATH = BASE_DIR / "config" / ".env"
load_dotenv(CONFIG_PATH)

client = OpenAI()

st.set_page_config(
    page_title="AI ìƒë‹´ ë¡œê·¸ ë¶„ì„",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
if "messages" not in st.session_state:
    st.session_state.messages = []

targets = list(AnswerTarget)
mentors = [get_chat_service(e) for e in targets]
mentor_map = {mentor.author_name: mentor for mentor in mentors}

# -------------------------------------------------------------------------
# 2. Helper í•¨ìˆ˜: ì°¨íŠ¸ ê·¸ë¦¬ê¸°
# -------------------------------------------------------------------------
def draw_chart(json_data):
    """JSON ë°ì´í„°ë¥¼ ë°›ì•„ Pandas DFë¡œ ë³€í™˜ í›„ Plotly ì°¨íŠ¸ ì¶œë ¥"""
    if not json_data:
        return

    try:
        # ë¬¸ìì—´ì´ë©´ JSON íŒŒì‹±, ë”•ì…”ë„ˆë¦¬ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        data = json.loads(json_data) if isinstance(json_data, str) else json_data

        # ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬
        if isinstance(data, dict) and "error" in data:
            st.error(f"ì„œë²„ ì—ëŸ¬: {data['error']}")
            return

        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ì¸ ê²½ìš° ì°¨íŠ¸ ìƒì„±
        if isinstance(data, list) and len(data) > 0:
            df = pd.DataFrame(data)
            fig = None 

            # (1) ê°ì • ë¶„ì„
            if "emotion" in df.columns:
                st.caption("ğŸ“Š ê°ì • ë¶„í¬ ë¹„ìœ¨")
                fig = px.pie(df, values='count', names='emotion', hole=0.4)
                fig.update_traces(textposition='inside', textinfo='percent+label')
            
            # (2) ë©˜í†  ë¹ˆë„
            elif "mento" in df.columns:
                st.caption("ğŸ§‘â€ğŸ« ë©˜í†  ìƒë‹´ ì ìœ ìœ¨")
                fig = px.pie(df, values='count', names='mento')
                fig.update_traces(textposition='inside', textinfo='percent+label')
            
            # (3) í‚¤ì›Œë“œ ìˆœìœ„
            elif "keyword" in df.columns:
                st.caption("ğŸ”‘ ê³ ë¯¼ í‚¤ì›Œë“œ ë¹„ìœ¨ (Top 10)")
                df_top10 = df.head(10) 
                fig = px.pie(df_top10, values='count', names='keyword', hole=0.3)
                fig.update_traces(textposition='inside', textinfo='percent+label')
                
                with st.expander("ìƒì„¸ ë°ì´í„° í‘œ ë³´ê¸°"):
                    st.dataframe(df)

            if fig:
                st.plotly_chart(fig, use_container_width=True)

    except (json.JSONDecodeError, TypeError):
        # JSONì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ê°€ tool outputìœ¼ë¡œ ì˜¬ ê²½ìš° ë¬´ì‹œí•˜ê±°ë‚˜ ë¡œê¹…
        pass
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")

# -------------------------------------------------------------------------
# 3. UI: í—¤ë” ë° ë©˜í†  ì»¨íŠ¸ë¡¤
# -------------------------------------------------------------------------
st.markdown(
    """
    <style>
        /* í† ìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ í¬ê¸° ì¡°ì ˆ */
        div[data-testid="stToast"] {
            width: 50% !important;       /* ê°€ë¡œ ë„ˆë¹„ë¥¼ í™”ë©´ì˜ 50%ë¡œ ì„¤ì • (ê¸°ë³¸ê°’ì€ ê³ ì • í”½ì…€) */
            max-width: 800px !important; /* ìµœëŒ€ ë„ˆë¹„ ì œí•œ */
            padding: 20px !important;    /* ë‚´ë¶€ ì—¬ë°±ì„ ëŠ˜ë ¤ ì‹œì›í•˜ê²Œ */
            font-size: 16px !important;  /* ê¸€ì í¬ê¸°ë„ ì•½ê°„ í‚¤ì›€ */
        }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("AI ìƒë‹´ ë¡œê·¸ ë¶„ì„")
st.markdown("""
    > **"ë°ì´í„°ë¡œ ë§ˆìŒì„ ì½ë‹¤"** > MCP ê¸°ë°˜ AI ì—ì´ì „íŠ¸ê°€ ìƒë‹´ DBë¥¼ ì‹¤ì‹œê°„ ë¶„ì„í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ë˜ì§€ë©´ íŠ¸ë Œë“œì™€ ê°ì •ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """)

with st.sidebar:
    selected_mentors = st.multiselect(
        "ë…¼í‰",
        options=list(mentor_map.keys()),
        placeholder="ë©˜í† ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        label_visibility="collapsed"
    )

    if st.button("âœ¨ ë©˜í†  í†µì°° ì‹¤í–‰", type="primary", use_container_width=True):
        if selected_mentors:
            target_data = "í˜„ì¬ íŠ¹ë³„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì¸ìƒ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”."
            
            # ëŒ€í™” ê¸°ë¡ ì—­ìˆœ íƒìƒ‰í•˜ì—¬ ë¶„ì„ ëŒ€ìƒ ì¶”ì¶œ
            found_data = False
            for msg in reversed(st.session_state.messages):
                if msg["role"] == "tool":
                    target_data = f"ìµœê·¼ ìƒë‹´ ë°ì´í„° ë¶„ì„ ê²°ê³¼: {msg['content']}"
                    found_data = True
                    break
                elif msg["role"] == "user":
                    target_data = f"ì‚¬ìš©ì ì§ˆë¬¸: {msg['content']}"
                    found_data = True
                    break
            
            if not found_data:
                st.toast("ë¶„ì„í•  ëŒ€í™” ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.", icon="â„¹ï¸")
            
            else:
                with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
                    for mentor_name in selected_mentors:
                        advice, _ = mentor_map[mentor_name].analysis_data(target_data)
    
                        # í† ìŠ¤íŠ¸ ëŒ€ì‹  í™•ì¥í˜• ë°•ìŠ¤ ì‚¬ìš©
                        with st.expander(f"ğŸ“© {mentor_name}ì˜ ë©”ì„¸ì§€ ë„ì°©", expanded=True):
                            st.write(advice)
                    # for mentor_name in selected_mentors:
                    #     advice, _ = mentor_map[mentor_name].analysis_data(target_data)
                        
                    #     # [ë³€ê²½ ì‚¬í•­]
                    #     # 1. ì±„íŒ… ê¸°ë¡(session_state)ì— ì €ì¥í•˜ëŠ” ì½”ë“œ ì‚­ì œ
                    #     # 2. st.toastë¡œ ê²°ê³¼ ì¶œë ¥ (icon ì˜µì…˜ ì¶”ê°€ë¡œ ì‹œê°ì  íš¨ê³¼)
                    #     st.toast(f"{advice}", icon=mentor_map[mentor_name]._get_avartar())
                    #     # show_advice_modal(mentor_name, advice)

st.divider()
for msg in st.session_state.messages:
    # (1) ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê°ì²´ê°€ ì„ì—¬ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜ (ì„ íƒì‚¬í•­ì´ë‚˜ ê¶Œì¥)
    if not isinstance(msg, dict):
        try:
            msg = msg.model_dump()
        except:
            continue # ë³€í™˜ ì•ˆ ë˜ë©´ ê±´ë„ˆëœ€

    # (2) ì—­í• ë³„ ì¶œë ¥
    if msg["role"] == "tool":
        with st.chat_message("assistant"):
            draw_chart(msg["content"])
            with st.expander("ë°ì´í„° ì›ë³¸ ë³´ê¸°"):
                st.code(msg["content"], language="json")
    
    elif msg["role"] != "system":
        # âš ï¸ ì¤‘ìš”: Tool Call ë©”ì‹œì§€ëŠ” contentê°€ Noneì¼ ìˆ˜ ìˆìŒ -> ì¶œë ¥í•˜ì§€ ì•ŠìŒ
        if msg.get("content"): 
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

# -------------------------------------------------------------------------
# 5. ì±„íŒ… ë¡œì§ (ìƒˆë¡œìš´ ì…ë ¥ ì²˜ë¦¬)
# -------------------------------------------------------------------------
if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: ì´ë²ˆ ë‹¬ ê³ ë¯¼ í‚¤ì›Œë“œ ì°¨íŠ¸ë¡œ ë³´ì—¬ì¤˜)"):
    
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # (2) LLM í˜¸ì¶œ
    today = datetime.now().strftime("%Y-%m-%d")
    system_msg = {"role": "system", "content": f"ë‹¹ì‹ ì€ ìƒë‹´ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today}ì…ë‹ˆë‹¤."}
    messages_to_send = [system_msg] + st.session_state.messages

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages_to_send,
        tools=tools_schema,
        tool_choice="auto"
    )
    
    response_msg = response.choices[0].message

    # (3) ë„êµ¬ í˜¸ì¶œ í™•ì¸
    if response_msg.tool_calls:
        tool_call = response_msg.tool_calls[0]
        func_name = tool_call.function.name
        func_args = json.loads(tool_call.function.arguments)
        
        # ì˜ë„ ì €ì¥ (assistantì˜ tool call ë©”ì‹œì§€)
        st.session_state.messages.append(response_msg)

        with st.chat_message("assistant"):
            # ìƒíƒœ í‘œì‹œ
            with st.status(f"ë°ì´í„° ë¶„ì„ ì¤‘... ({func_name})", expanded=True) as status:
                st.write(f"ìš”ì²­ ì¸ì: {func_args}")
                tool_result = asyncio.run(mcp_query_db(func_name, func_args))
                status.write("âœ… ë°ì´í„° ì¡°íšŒ ì™„ë£Œ!")
                status.update(label="ë¶„ì„ ì™„ë£Œ", state="complete", expanded=False)
            
            # ğŸ”¥ [ì¦‰ì‹œ ë Œë”ë§] í˜„ì¬ í„´ì˜ ì°¨íŠ¸ ê·¸ë¦¬ê¸°
            draw_chart(tool_result)

        # ë„êµ¬ ê²°ê³¼ ì €ì¥
        st.session_state.messages.append({
            "role": "tool",
            "tool_call_id": tool_call.id,
            "content": tool_result
        })

        # ìµœì¢… ë‹µë³€ ìƒì„±
        final_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[system_msg] + st.session_state.messages
        )
        final_answer = final_response.choices[0].message.content
        
        st.session_state.messages.append({"role": "assistant", "content": final_answer})
        with st.chat_message("assistant"):
            st.write(final_answer)

    else:
        # ì¼ë°˜ ëŒ€í™”
        final_answer = response_msg.content
        st.session_state.messages.append({"role": "assistant", "content": final_answer})
        with st.chat_message("assistant"):
            st.write(final_answer)