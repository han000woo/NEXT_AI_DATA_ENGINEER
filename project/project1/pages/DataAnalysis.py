import asyncio
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st
import json
import pandas as pd  # ğŸ‘ˆ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•´ Pandas ì¶”ê°€
from backend.mcp_service import mcp_query_db
from config.mcp_tool import tools_schema
from datetime import datetime
import plotly.express as px  # ğŸ‘ˆ Plotly ì„í¬íŠ¸ ì¶”ê°€!

# ... (ê²½ë¡œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì • ê¸°ì¡´ ë™ì¼) ...
BASE_DIR = Path(__file__).resolve().parents[1]
CONFIG_PATH = BASE_DIR / "config" / ".env"
load_dotenv(CONFIG_PATH)

client = OpenAI()


st.set_page_config(
    page_title="AI ìƒë‹´ ë¡œê·¸ ë¶„ì„",
    layout="wide"  # ì°¨íŠ¸ë¥¼ ë„“ê²Œ ë³´ê¸° ìœ„í•´ wide ëª¨ë“œ ì„¤ì •
)

# ==========================================
# [Header] ëŒ€ì‹œë³´ë“œ ì†Œê°œ ë° ìš”ì•½
# ==========================================
st.title("AI ìƒë‹´ ë¡œê·¸ ë¶„ì„")

st.markdown("""
> **"ë°ì´í„°ë¡œ ë§ˆìŒì„ ì½ë‹¤"** > ì´ ëŒ€ì‹œë³´ë“œëŠ” **MCP(Model Context Protocol)** ê¸°ë°˜ì˜ AI ì—ì´ì „íŠ¸ê°€ ìƒë‹´ DBë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.  
> ë³µì¡í•œ SQL ì¿¼ë¦¬ ì—†ì´, **ìì—°ì–´**ë¡œ ì§ˆë¬¸í•˜ë©´ ìƒë‹´ íŠ¸ë Œë“œ, ê°ì • ìƒíƒœ, í‚¤ì›Œë“œ ë“±ì„ **ì‹œê°í™”**í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.
""")


st.divider() # êµ¬ë¶„ì„ 

# ==========================================
# [Helper] ì°¨íŠ¸ ê·¸ë¦¬ê¸° í•¨ìˆ˜
# JSON ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ì ì ˆí•œ ì°¨íŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
# ==========================================

def draw_chart(json_data):
    # 1. ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
    if not json_data:
        return

    try:
        # ë¬¸ìì—´ì´ë©´ JSON íŒŒì‹±
        if isinstance(json_data, str):
            # ë””ë²„ê¹…: print(f"[DEBUG] raw: {json_data}")
            data = json.loads(json_data)
        else:
            data = json_data

        # ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬
        if isinstance(data, dict) and "error" in data:
            st.error(f"ì„œë²„ ì—ëŸ¬: {data['error']}")
            return

        # 2. ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì°¨íŠ¸ ê·¸ë¦¬ê¸°
        if isinstance(data, list) and len(data) > 0:
            df = pd.DataFrame(data)
            
            fig = None # ì°¨íŠ¸ ê°ì²´ ì´ˆê¸°í™”

            # (1) ê°ì • ë¶„ì„ (Pie Chart)
            if "emotion" in df.columns:
                st.caption("ğŸ“Š ê°ì • ë¶„í¬ ë¹„ìœ¨")
                # ë„ë„› ì°¨íŠ¸ ìŠ¤íƒ€ì¼ (hole=0.4)
                fig = px.pie(df, values='count', names='emotion', hole=0.4)
                fig.update_traces(textposition='inside', textinfo='percent+label')
            
            # (2) ë©˜í†  ë¹ˆë„ (Pie Chart)
            elif "mento" in df.columns:
                st.caption("ğŸ§‘â€ğŸ« ë©˜í†  ìƒë‹´ ì ìœ ìœ¨")
                fig = px.pie(df, values='count', names='mento')
                fig.update_traces(textposition='inside', textinfo='percent+label')
            
            # (3) í‚¤ì›Œë“œ ìˆœìœ„ (Pie Chart)
            elif "keyword" in df.columns:
                st.caption("ğŸ”‘ ê³ ë¯¼ í‚¤ì›Œë“œ ë¹„ìœ¨ (Top 10)")
                # í‚¤ì›Œë“œê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ë³´ê¸° í‰í•˜ë¯€ë¡œ ìƒìœ„ 10ê°œë§Œ ìë¦„
                df_top10 = df.head(10) 
                fig = px.pie(df_top10, values='count', names='keyword', hole=0.3)
                fig.update_traces(textposition='inside', textinfo='percent+label')
                
                # í‚¤ì›Œë“œëŠ” í‘œë„ ê°™ì´ ë³´ì—¬ì£¼ëŠ” ê²Œ ì¢‹ìŒ
                with st.expander("ìƒì„¸ ë°ì´í„° í‘œ ë³´ê¸°"):
                    st.dataframe(df)

            # 3. Streamlitì— ì°¨íŠ¸ ì¶œë ¥
            if fig:
                st.plotly_chart(fig, use_container_width=True)

    except json.JSONDecodeError:
        st.warning("ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")

# ==========================================
# [FIX 1] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ==========================================
if "messages" not in st.session_state:
    st.session_state.messages = []


# ==========================================
# [Main] ì±„íŒ… ë¡œì§
# ==========================================
if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: ì´ë²ˆ ë‹¬ ê³ ë¯¼ í‚¤ì›Œë“œ ì°¨íŠ¸ë¡œ ë³´ì—¬ì¤˜)"):
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # 2. LLM í˜¸ì¶œ ì¤€ë¹„
    today = datetime.now().strftime("%Y-%m-%d")
    system_msg = {"role": "system", "content": f"ë‹¹ì‹ ì€ ìƒë‹´ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today}ì…ë‹ˆë‹¤."}
    
    messages_to_send = [system_msg] + st.session_state.messages

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages_to_send,
        tools=tools_schema,
        tool_choice="auto"
    )
    
    response_msg = response.choices[0].message


    # 3. ë„êµ¬ í˜¸ì¶œ í™•ì¸
    if response_msg.tool_calls:
        tool_call = response_msg.tool_calls[0]
        func_name = tool_call.function.name
        func_args = json.loads(tool_call.function.arguments)
        
        # (1) AIì˜ ì˜ë„ ì €ì¥
        st.session_state.messages.append(response_msg)

        with st.chat_message("assistant"):
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            with st.status(f"ğŸ› ï¸ ë°ì´í„° ë¶„ì„ ì¤‘... ({func_name})", expanded=True) as status:
                st.write(f"ìš”ì²­ ì¸ì: {func_args}")
                
                # (2) MCP ì„œë²„ í˜¸ì¶œ -> ì´ì œ JSON ë¬¸ìì—´ì´ ì˜´
                tool_result = asyncio.run(mcp_query_db(func_name, func_args))
                
                status.write("âœ… ë°ì´í„° ì¡°íšŒ ì™„ë£Œ!")
                status.update(label="ë¶„ì„ ì™„ë£Œ", state="complete", expanded=False)
            
            # ğŸ”¥ [í•µì‹¬] ë°ì´í„°ë¥¼ ë°›ìë§ˆì ì°¨íŠ¸ë¡œ ì‹œê°í™”!

            draw_chart(tool_result)

        # (3) ë„êµ¬ ê²°ê³¼(JSON ë¬¸ìì—´)ë¥¼ historyì— ì €ì¥ (LLM ì°¸ê³ ìš© + ë‚˜ì¤‘ì— ë‹¤ì‹œ ê·¸ë¦¬ê¸°ìš©)
        st.session_state.messages.append({
            "role": "tool",
            "tool_call_id": tool_call.id,
            "content": tool_result
        })

        # (4) ìµœì¢… ë‹µë³€ ìƒì„± (LLMì€ JSONì„ ë³´ê³  ìš”ì•½ ë©˜íŠ¸ë¥¼ ì‘ì„±)
        final_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[system_msg] + st.session_state.messages
        )
        final_answer = final_response.choices[0].message.content
        
        st.session_state.messages.append({"role": "assistant", "content": final_answer})
        with st.chat_message("assistant"):
            st.write(final_answer)

    else:
        # ì¼ë°˜ ëŒ€í™”
        final_answer = response_msg.content
        st.session_state.messages.append({"role": "assistant", "content": final_answer})
        with st.chat_message("assistant"):
            st.write(final_answer)